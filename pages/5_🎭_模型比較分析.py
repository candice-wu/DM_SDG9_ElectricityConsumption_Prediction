import streamlit as st
import pandas as pd
import plotly.graph_objects as go
import plotly.express as px
import altair as alt
from src.data_preprocessing import DataPreprocessor
from src.ui_components import render_app_info, render_data_status
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error, confusion_matrix, accuracy_score
from sklearn.model_selection import train_test_split
from sklearn.inspection import permutation_importance
from sklearn.ensemble import HistGradientBoostingRegressor
import numpy as np

# --- Page Configuration ---
st.set_page_config(page_title="æ¨¡å‹æ¯”è¼ƒåˆ†æ", page_icon="ğŸ­", layout="wide")

# --- Constants & Helper Functions ---
MODEL_NAME_MAPPING = {
    "ç·šæ€§è¿´æ­¸ (Linear Regression)": "LinearRegression",
    "æ±ºç­–æ¨¹è¿´æ­¸ (Decision Tree Regression)": "DecisionTreeRegressor",
    "æ¢¯åº¦æå‡æ¨¹è¿´æ­¸ (HistGradient)": "HistGradientBoostingRegressor",
    "æ”¯æŒå‘é‡è¿´æ­¸ (SVR)": "SVR",
    "æ¢¯åº¦æå‡æ¨¹è¿´æ­¸ (LightGBM)": "LGBMRegressor"
}

# --- Colors ---
HIGHLIGHT_COLOR = "#4481D7"
MULTI_MODEL_COLORS = ['#3ABBDE', '#DD5C6A', '#F5C65D', '#D96015', '#9FCE63']
SINGLE_MODEL_COLOR = '#BC72A7'
FEATURE_IMPORTANCE_COLOR = '#F5C65D'


def get_styled_text(text):
    return f'<span style="color:{HIGHLIGHT_COLOR}; font-weight:bold;">{text}</span>'


# --- Main App ---
st.title("ğŸ­ æ¨¡å‹æ¯”è¼ƒèˆ‡é€²éšåˆ†æ")

# --- Data Loading and Caching ---
def load_data():
    if 'data_loaded' not in st.session_state or not st.session_state.data_loaded:
        return None, None, None
    cleaned_df = st.session_state['cleaned_df']
    preprocessor = st.session_state['preprocessor']
    return cleaned_df, preprocessor, st.session_state.get('original_df')


@st.cache_resource(show_spinner="æ­£åœ¨ç‚ºæ‰€æœ‰æ¨¡å‹è¨“ç·´ä¸¦å¿«å–çµæœ...")
def get_all_models_data(_preprocessor, _X_full, _y_full, models_dict):
    all_models_data = {}
    for model_name_chinese, model_name_english in models_dict.items():
        try:
            # Correctly unpack the 5 values returned from the refactored function
            model, metrics, X_test_scaled, y_test, y_pred = _preprocessor.train_predict_evaluate_model(
                model_name_english, _X_full, _y_full, test_size=0.2, random_state=42
            )
            # Store all the returned data, not just model and predictions
            all_models_data[model_name_chinese] = {
                "model": model,
                "metrics": metrics,
                "predictions": y_pred,
                "X_test_scaled": X_test_scaled,
                "y_test": y_test
            }
        except Exception as e:
            st.warning(f"ç„¡æ³•ç‚ºæ¨¡å‹ '{model_name_chinese}' ç”¢ç”Ÿçµæœï¼š{e}")
            all_models_data[model_name_chinese] = None # Mark failed model
    return all_models_data


cleaned_df, preprocessor, original_df = load_data()

if cleaned_df is None or preprocessor is None:
    st.warning("â¬…ï¸ è«‹å…ˆè‡³ã€ŒğŸ“„ è³‡æ–™æ¢ç´¢èˆ‡æ¸…ç†ã€é é¢ä¸Šå‚³ä¸¦æ¸…ç†è³‡æ–™")
    st.stop()

# Render sidebar elements
render_app_info()
render_data_status(cleaned_df)

st.info("""
æ­¤é é¢æä¾›ä¸€å€‹äº’å‹•å¼å„€è¡¨æ¿ï¼Œç”¨æ–¼æ·±å…¥æ¯”è¼ƒå’Œè¨ºæ–·åœ¨ã€Œç”¨é›»é‡é æ¸¬ã€é é¢ä¸Šè¨“ç·´çš„å„å€‹è¿´æ­¸æ¨¡å‹ä¹‹æ•ˆèƒ½èˆ‡è¡Œç‚º
- **é æ¸¬å€¼ vs. å¯¦éš›å€¼åœ–**ï¼šç›´è§€åœ°è©•ä¼°æ¨¡å‹çš„æ•´é«”æº–ç¢ºæ€§å’Œæ½›åœ¨åå·®
- **æ®˜å·®åœ–**ï¼šç”¨æ–¼è¨ºæ–·æ¨¡å‹çš„ç³»çµ±æ€§éŒ¯èª¤ï¼Œç†æƒ³çš„æ®˜å·®æ‡‰éš¨æ©Ÿåˆ†ä½ˆ
- **ç‰¹å¾µé‡è¦æ€§åœ–**ï¼šæ­ç¤ºæ¨¡å‹åœ¨é€²è¡Œé æ¸¬æ™‚æœ€ä¾è³´å“ªäº›ç‰¹å¾µ
- **æ··æ·†çŸ©é™£åˆ†æ**ï¼šå°‡é€£çºŒé æ¸¬å€¼è½‰æ›ç‚ºç´šè·ï¼Œè©•ä¼°æ¨¡å‹åœ¨å„ç´šè·ä¸Šçš„åˆ†é¡æº–ç¢ºåº¦
""")

X_full, y_full, feature_names, _ = preprocessor.get_prediction_data(cleaned_df)
X_train, X_test, y_train, y_test = train_test_split(
    X_full, y_full, test_size=0.2, random_state=42
)
all_models_data = get_all_models_data(preprocessor, X_full, y_full, MODEL_NAME_MAPPING)


# --- Plotting Functions ---
def plot_prediction_vs_actual(models_data, y_true_series, selected_models, colors):
    fig = go.Figure()
    for i, model_name in enumerate(selected_models):
        if model_name in models_data and 'predictions' in models_data[model_name]:
            y_pred = models_data[model_name]['predictions']
            fig.add_trace(go.Scatter(
                x=y_true_series,
                y=y_pred,
                mode='markers',
                name=model_name,
                marker=dict(opacity=0.7, color=colors[i % len(colors)])
            ))

    if models_data:
        preds = [
            md['predictions']
            for md in models_data.values()
            if md.get('predictions') is not None and md['predictions'].size > 0
        ]
        if preds:
            min_val = min(y_true_series.min(), *(p.min() for p in preds))
            max_val = max(y_true_series.max(), *(p.max() for p in preds))
            fig.add_shape(
                type='line',
                x0=min_val, y0=min_val,
                x1=max_val, y1=max_val,
                line=dict(color='Gray', width=3, dash='dash')
            )

    fig.update_layout(
        title_text="é æ¸¬å€¼ vs. å¯¦éš›å€¼ (Prediction vs. Actual)",
        xaxis_title="å¯¦éš›ç”¨é›»é‡ (Actual Usage)",
        yaxis_title="é æ¸¬ç”¨é›»é‡ (Predicted Usage)",
        legend_title="æ¨¡å‹",
        height=600
    )
    return fig


def plot_residuals(models_data, y_true_series, selected_models, colors):
    fig = go.Figure()
    for i, model_name in enumerate(selected_models):
        if model_name in models_data and 'predictions' in models_data[model_name]:
            y_pred = models_data[model_name]['predictions']
            residuals = y_true_series - y_pred
            fig.add_trace(go.Scatter(
                x=y_pred,
                y=residuals,
                mode='markers',
                name=model_name,
                marker=dict(opacity=0.7, color=colors[i % len(colors)])
            ))

    fig.add_hline(y=0, line_width=3, line_dash="dash", line_color="Gray")
    fig.update_layout(
        title_text="æ®˜å·®åœ– (Residuals Plot)",
        xaxis_title="é æ¸¬ç”¨é›»é‡ (Predicted Usage)",
        yaxis_title="æ®˜å·® (Actual - Predicted)",
        legend_title="æ¨¡å‹",
        height=500
    )
    return fig


def plot_feature_importance(model_obj, features, color, X_test_scaled=None, y_test=None):
    importance = None
    if isinstance(model_obj, HistGradientBoostingRegressor):
        if X_test_scaled is not None and y_test is not None:
            with st.spinner("æ­£åœ¨è¨ˆç®—æ’åˆ—é‡è¦æ€§..."):
                result = permutation_importance(model_obj, X_test_scaled, y_test, n_repeats=10, random_state=42)
                importance = result.importances_mean
        else:
            return None, None # Cannot calculate without test data
    elif hasattr(model_obj, 'feature_importances_'):
        importance = model_obj.feature_importances_
    elif hasattr(model_obj, 'coef_'):
        importance = np.abs(model_obj.coef_.flatten())

    if importance is not None and len(importance) == len(features):
        df = pd.DataFrame({
            'Feature': features,
            'Importance': importance
        }).sort_values('Importance', ascending=False)

        chart = alt.Chart(df).mark_bar(color=color).encode(
            x=alt.X('Importance', title='é‡è¦æ€§åˆ†æ•¸'),
            y=alt.Y('Feature', sort='-x', title='ç‰¹å¾µ')
        ).properties(title='ç‰¹å¾µé‡è¦æ€§')

        return chart, df.head(3)

    return None, None


def discretize_data(y_true, num_bins):
    try:
        _, bin_edges = pd.qcut(y_true, q=num_bins, retbins=True, duplicates='drop')

        if num_bins == 2:
            prefixes = ['ä½', 'é«˜']
        elif num_bins == 3:
            prefixes = ['ä½', 'ä¸­', 'é«˜']
        elif num_bins == 4:
            prefixes = ['ä½', 'ä¸­ä½', 'ä¸­é«˜', 'é«˜']
        else:
            prefixes = ['æ¥µä½', 'ä½', 'ä¸­', 'é«˜', 'æ¥µé«˜']

        bin_labels = [
            f"{prefixes[i]}ç”¨é‡ ({bin_edges[i]:.2f} - {bin_edges[i+1]:.2f}]"
            for i in range(len(bin_edges) - 1)
        ]

        y_true_discrete = pd.cut(
            y_true,
            bins=bin_edges,
            labels=bin_labels,
            include_lowest=True,
            right=True
        )
        return y_true_discrete, bin_labels, bin_edges
    except Exception:
        return None, [], []


def plot_confusion_matrix(cm, labels):
    fig = px.imshow(
        cm,
        labels=dict(x="é æ¸¬ç´šè·", y="å¯¦éš›ç´šè·", color="æ¬¡æ•¸"),
        x=labels, y=labels,
        text_auto=True,
        color_continuous_scale=px.colors.diverging.Spectral_r
    )
    fig.update_layout(
        title_text='æ··æ·†çŸ©é™£',
        height=500,
        xaxis={'side': 'top', 'tickangle': -45}
    )
    return fig


# --- UI Rendering ---
st.header("ğŸ¨ å¤šæ¨¡å‹æ•ˆèƒ½è¦–è¦ºåŒ–æ¯”è¼ƒ")
model_options = list(all_models_data.keys())

if not model_options:
    st.error("ç„¡ä»»ä½•æ¨¡å‹æˆåŠŸè¼‰å…¥ï¼Œè«‹æª¢æŸ¥ `get_all_models_data` å‡½å¼ã€‚")
    st.stop()

selected_models = st.multiselect("é¸æ“‡è¦æ¯”è¼ƒçš„æ¨¡å‹ï¼š", options=model_options, default=model_options)

if selected_models:
    colors = [SINGLE_MODEL_COLOR] if len(selected_models) == 1 else MULTI_MODEL_COLORS

    st.subheader("ğŸ é æ¸¬å€¼ vs. å¯¦éš›å€¼åˆ†æ")
    fig1 = plot_prediction_vs_actual(all_models_data, y_test, selected_models, colors)
    st.plotly_chart(fig1, use_container_width=True)

    with st.expander("ğŸ“Š çµè«–ï¼šé æ¸¬å€¼ vs. å¯¦éš›å€¼åˆ†æ", expanded=True):
        metrics = {
            name: {
                "RÂ²": r2_score(y_test, all_models_data[name]['predictions']),
                "RMSE": np.sqrt(mean_squared_error(y_test, all_models_data[name]['predictions']))
            }
            for name in selected_models
            if name in all_models_data and all_models_data[name]
        }

        if metrics:
            metrics_df = pd.DataFrame(metrics).T.sort_values("RÂ²", ascending=False)
            st.dataframe(
                metrics_df.style
                .format("{:.4f}")
                .highlight_max(axis=0, subset="RÂ²", color="#9ACD32")
                .highlight_min(axis=0, subset="RMSE", color="#F08080")
            )

            best_r2_model = metrics_df["RÂ²"].idxmax()
            best_rmse_model = metrics_df["RMSE"].idxmin()

            st.markdown("---")
            st.markdown(f"""
            **çµè«–åˆ†æï¼š**<br>
            - å®Œç¾çš„æ¨¡å‹ï¼Œå…¶æ•¸æ“šé»æœƒè½åœ¨ {get_styled_text("45 åº¦çš„å°è§’ç·š")} ä¸Š
            - {get_styled_text('RÂ²')} æ„ˆæ¥è¿‘ {get_styled_text('1')} è¡¨ç¤ºæ¨¡å‹è§£é‡‹è®Šç•°èƒ½åŠ›æ„ˆ{get_styled_text("å¼·")}ï¼Œ{get_styled_text('RMSE')} æ„ˆ{get_styled_text('å°')}è¡¨ç¤ºé æ¸¬èª¤å·®æ„ˆ{get_styled_text("ä½")}
            - RÂ² è¡¨ç¾æœ€å¥½çš„æ¨¡å‹ç‚º **{get_styled_text(best_r2_model)}** (RÂ² = {metrics_df.loc[best_r2_model, 'RÂ²']:.4f})
            - RMSE è¡¨ç¾æœ€å¥½çš„æ¨¡å‹ç‚º **{get_styled_text(best_rmse_model)}** (RMSE = {metrics_df.loc[best_rmse_model, 'RMSE']:.4f})
            - RÂ² å’Œ RMSE ç¶œåˆè¡¨ç¾æœ€ä½³çš„æ¨¡å‹ç‚º **{get_styled_text(best_r2_model)}**
            """, unsafe_allow_html=True)

    st.markdown("---")

    st.subheader("ğŸ§© æ®˜å·®åˆ†æ")
    fig2 = plot_residuals(all_models_data, y_test, selected_models, colors)
    st.plotly_chart(fig2, use_container_width=True)

    with st.expander("ğŸ“Š çµè«–ï¼šæ®˜å·®åˆ†æ", expanded=True):
        res_stats = {
            name: {
                "å¹³å‡å€¼": (y_test - all_models_data[name]['predictions']).mean(),
                "æ¨™æº–å·®": (y_test - all_models_data[name]['predictions']).std()
            }
            for name in selected_models
            if name in all_models_data and all_models_data[name]
        }

        if res_stats:
            res_stats_df = pd.DataFrame(res_stats).T.sort_values("æ¨™æº–å·®")

            st.dataframe(
                res_stats_df.style
                .format("{:.4f}")
                .highlight_min(axis=0, subset="æ¨™æº–å·®", color="#F08080")
                .apply(lambda x: ['background-color: #9ACD32' if abs(v) < 1e-3 else '' for v in x],
                       subset=['å¹³å‡å€¼'])
            )

            best_std_model = res_stats_df["æ¨™æº–å·®"].idxmin()

            st.markdown("---")
            st.markdown(f"""
            **çµè«–åˆ†æï¼š**<br>
            - ç†æƒ³çš„æ®˜å·®åœ–ä¸­ï¼Œè³‡æ–™é»æ‡‰éš¨æ©Ÿåˆ†ä½ˆåœ¨{get_styled_text('é›¶é»æ°´å¹³ç·š')}å‘¨åœï¼Œæ²’æœ‰æ˜é¡¯çš„æ¨¡å¼æˆ–è¶¨å‹¢ï¼Œæœ‰åŠ©æ–¼æ¸›å°‘ç³»çµ±æ€§åå·®
            - {get_styled_text('æ®˜å·®å¹³å‡å€¼')}æ‡‰æ¥è¿‘ {get_styled_text('é›¶')}ï¼Œ{get_styled_text('æ¨™æº–å·®')} æ„ˆ {get_styled_text('å°')}ï¼Œè¡¨ç¤ºé æ¸¬æ›´ {get_styled_text('ç©©å®š')}  
            - ç›®å‰æ®˜å·®æ¨™æº–å·®æœ€å°çš„æ¨¡å‹ç‚º {get_styled_text(best_std_model)} æ¨™æº–å·® = {res_stats_df.loc[best_std_model, 'æ¨™æº–å·®']:.4f}
            """, unsafe_allow_html=True)

st.markdown("---")

# --- Single Model Analysis ---
st.header("ğŸª å–®ä¸€æ¨¡å‹æ·±åº¦åˆ†æ")
col1, col2 = st.columns(2)

with col1:
    st.subheader("â­ ç‰¹å¾µé‡è¦æ€§åˆ†æ")
    fi_options = [
        name for name, data in all_models_data.items()
        if data and (
            hasattr(data.get('model'), 'feature_importances_') or 
            hasattr(data.get('model'), 'coef_') or
            isinstance(data.get('model'), HistGradientBoostingRegressor)
        )
    ]

    if not fi_options:
        st.warning("âš ï¸ ç›®å‰è¼‰å…¥çš„æ¨¡å‹å‡ä¸æ”¯æ´ç›´æ¥çš„ç‰¹å¾µé‡è¦æ€§åˆ†æã€‚")
    else:
        model_fi = st.selectbox("é¸æ“‡æ¨¡å‹ä»¥åˆ†æç‰¹å¾µé‡è¦æ€§ï¼š", options=fi_options, key="fi_model")
        if model_fi and model_fi in all_models_data:
            model_info = all_models_data[model_fi]
            # We need the specific test set used for this model, which is now stored
            X_test_scaled_model = model_info.get("X_test_scaled")
            y_test_model = model_info.get("y_test")

            if X_test_scaled_model is not None and y_test_model is not None:
                chart, top_feats = plot_feature_importance(
                    model_info["model"],
                    feature_names,
                    FEATURE_IMPORTANCE_COLOR,
                    X_test_scaled_model,
                    y_test_model
                )
                if chart is not None:
                    st.altair_chart(chart, use_container_width=True)
                    with st.expander("ğŸ“Š çµè«–ï¼šç‰¹å¾µé‡è¦æ€§åˆ†æ", expanded=True):
                        st.markdown("##### æ–¹æ³•å®šç¾©")
                        st.markdown(f"""
                            - æ­¤åˆ†ææœ‰åŠ©æ–¼ç†è§£æ¨¡å‹çš„æ±ºç­–éç¨‹ï¼Œä¸¦å¯ç”¨æ–¼ç‰¹å¾µé¸æ“‡èˆ‡å·¥ç¨‹
                                - å„ç‰¹å¾µçš„ç›¸å°é‡è¦æ€§æœƒå½±éŸ¿æ¨¡å‹é€²è¡Œé æ¸¬çš„ç¨‹åº¦
                                - é‡è¦æ€§åˆ†æ•¸æ„ˆ {get_styled_text('é«˜')} å‰‡å½±éŸ¿æ„ˆ {get_styled_text('å¤§')}ï¼Œæœ‰åŠ©æ–¼ç†è§£é æ¸¬é‚è¼¯èˆ‡é—œéµå› å­
                            - å°æ–¼ {get_styled_text('ç·šæ€§è¿´æ­¸ (Linear Regression)')} æ¨¡å‹ï¼Œä½¿ç”¨ {get_styled_text('ä¿‚æ•¸çµ•å°å€¼')} ä¾†è©•ä¼°ç‰¹å¾µå½±éŸ¿åŠ›
                            - ä»¥ä¸‹ä¸‰å¤§æ¨¡å‹ï¼Œä½¿ç”¨ {get_styled_text('å…§å»ºç‰¹å¾µé‡è¦æ€§ (Feature Importances)')} å±¬æ€§ä¾†è©•ä¼°ç‰¹å¾µå½±éŸ¿åŠ›
                                - {get_styled_text('æ±ºç­–æ¨¹è¿´æ­¸ (Decision Tree Regression)')}
                                - {get_styled_text('æ¢¯åº¦æå‡æ¨¹è¿´æ­¸ (LightGBM)')}
                                - {get_styled_text('æ¢¯åº¦æå‡æ¨¹è¿´æ­¸ (HistGradient)')}
                                - å…§å»ºç‰¹å¾µé‡è¦æ€§åŸºæ–¼ç‰¹å¾µåœ¨æ¨¹çµæ§‹ä¸­åˆ†è£‚ç¯€é»çš„è²¢ç»åº¦è¨ˆç®—
                            - {get_styled_text('æ¢¯åº¦æå‡æ¨¹è¿´æ­¸ (HistGradient)')} ä½¿ç”¨ {get_styled_text('æ’åˆ—é‡è¦æ€§ (Permutation Importance)')} æ–¹æ³•è©•ä¼°ç‰¹å¾µå½±éŸ¿åŠ›
                                - æ’åˆ—é‡è¦æ€§é€ééš¨æ©Ÿæ‰“äº‚æ¯å€‹ç‰¹å¾µçš„å€¼ï¼Œè§€å¯Ÿæ¨¡å‹é æ¸¬æ€§èƒ½çš„è®ŠåŒ–ä¾†è©•ä¼°è©²ç‰¹å¾µçš„é‡è¦æ€§
                            - å°æ–¼ {get_styled_text('æ”¯æŒå‘é‡è¿´æ­¸ (SVR)')} æ¨¡å‹ï¼Œå› ç‚ºä½¿ç”¨{get_styled_text('éç·šæ€§æ ¸å¿ƒ')}ï¼Œç„¡æ³•ç›´æ¥è©•ä¼°ç‰¹å¾µé‡è¦æ€§
                        """, unsafe_allow_html=True)

                        st.markdown("---")
                        st.markdown("##### æ•¸æ“šç‰¹æ€§")
                        st.markdown(f"æ­¤æ¨¡å‹ **{get_styled_text(model_fi)}** æœ€é‡è¦–çš„å‰ä¸‰å¤§ç‰¹å¾µç‚ºï¼š", unsafe_allow_html=True)

                        for _, feat in top_feats.iterrows():
                            st.markdown(
                                f"- **{get_styled_text(feat['Feature'])}** (é‡è¦æ€§åˆ†æ•¸ = {feat['Importance']:.4f})",
                                unsafe_allow_html=True
                            )
                else:
                    st.info(f"æ¨¡å‹ã€Œ{model_fi}ã€ä¸æä¾›ç›´æ¥çš„ç‰¹å¾µé‡è¦æ€§å±¬æ€§ï¼ˆä¾‹å¦‚ï¼šSVR éç·šæ€§æ ¸å¿ƒï¼‰ã€‚")
            else:
                st.error("æ¨¡å‹è³‡æ–™ä¸å®Œæ•´ï¼Œç¼ºå°‘é€²è¡Œç‰¹å¾µé‡è¦æ€§åˆ†ææ‰€éœ€çš„æ¸¬è©¦é›†ã€‚")

with col2:
    st.subheader("ğŸ§® ç´šè·é æ¸¬æº–ç¢ºåº¦è©•ä¼° (æ··æ·†çŸ©é™£)")
    model_cm = st.selectbox("é¸æ“‡æ¨¡å‹ä»¥ç”¢ç”Ÿæ··æ·†çŸ©é™£ï¼š", options=model_options, key="cm_model")
    num_bins = st.slider("é¸æ“‡ç”¨é›»é‡ç´šè·æ•¸é‡ (åˆ†ä½æ•¸)ï¼š", 2, 5, 3, key="cm_bins")

    if model_cm and model_cm in all_models_data:
        y_true_discrete, bin_labels, bin_edges = discretize_data(y_test, num_bins)
        if y_true_discrete is not None and not y_true_discrete.empty:
            y_pred = all_models_data[model_cm]['predictions']

            # same discretization rule for prediction
            y_pred_discrete = pd.cut(
                y_pred,
                bins=bin_edges,
                labels=bin_labels,
                include_lowest=True,
                right=True
            )

            # Handle predictions out of range
            out_of_range_label = "é æ¸¬è¶…å‡ºç¯„åœ"
            has_out_of_range = y_pred_discrete.isnull().any()

            final_labels = bin_labels.copy()
            if has_out_of_range:
                y_pred_discrete = y_pred_discrete.add_categories(out_of_range_label).fillna(out_of_range_label)
                if out_of_range_label not in final_labels:
                    final_labels.append(out_of_range_label)
            
            # Ensure y_pred_discrete does not contain categories not in y_true_discrete unless it's the out_of_range_label
            y_pred_discrete = y_pred_discrete.astype(pd.CategoricalDtype(categories=final_labels))


            cm = confusion_matrix(y_true_discrete, y_pred_discrete, labels=final_labels)
            fig3 = plot_confusion_matrix(cm, final_labels)
            st.plotly_chart(fig3, use_container_width=True)

            with st.expander("ğŸ“Š çµè«–ï¼šæ··æ·†çŸ©é™£åˆ†æ", expanded=True):
                # Calculate accuracy excluding out-of-range predictions if they exist
                valid_indices = y_pred_discrete != out_of_range_label
                accuracy = accuracy_score(y_true_discrete[valid_indices], y_pred_discrete[valid_indices]) if valid_indices.any() else 0

                st.markdown("##### æ–¹æ³•å®šç¾©")
                st.markdown(f"""
                            - æ··æ·†çŸ©é™£å±•ç¤ºæ¨¡å‹åœ¨ä¸åŒã€Œç”¨é›»é‡ç´šè·ã€çš„åˆ†é¡è¡¨ç¾
                            - æ¯å€‹æ ¼å­ä¸­çš„æ•¸å€¼ä»£è¡¨æ¨¡å‹é æ¸¬è½åœ¨è©²ç´šè·çš„æ¬¡æ•¸
                                - å°è§’ç·šä¸Šçš„æ•¸å€¼ä»£è¡¨æ­£ç¢ºé æ¸¬
                                - éå°è§’ç·šå‰‡ç‚ºéŒ¯èª¤é æ¸¬
                            - æº–ç¢ºåº¦è¨ˆç®—æ–¹å¼ç‚ºï¼šæ­£ç¢ºé æ¸¬æ¬¡æ•¸ / ç¸½é æ¸¬æ¬¡æ•¸
                            """, unsafe_allow_html=True
                            )                
                if has_out_of_range:
                    st.markdown(f"""
                                - é—œæ–¼ã€Œ{get_styled_text(out_of_range_label)}ã€ï¼š
                                    - ç·šæ€§è¿´æ­¸ã€æ¢¯åº¦æå‡ç­‰æ¨¡å‹å¯èƒ½æœƒå¤–æ’ (extrapolation)ï¼Œå°è‡´é æ¸¬å€¼è¶…å‡ºè¨“ç·´è³‡æ–™çš„ç¯„åœ
                                    - æ­¤æ¨¡å‹ {get_styled_text(model_cm)} ä»£è¡¨é æ¸¬å€¼è¶…å‡ºæ¸¬è©¦è³‡æ–™çš„åˆ†ä½æ•¸ç¯„åœ
                                    """, unsafe_allow_html=True)


                st.markdown("---")
                st.markdown("##### æ•¸æ“šç‰¹æ€§")
                st.markdown(f"""
                            æ­¤æ¨¡å‹ {get_styled_text(model_cm)} æ•´é«”æº–ç¢ºåº¦ç‚º **{get_styled_text(f"{accuracy:.4%}")}**
                            """, unsafe_allow_html=True
                            )

        else:
            st.error(f"ç„¡æ³•å°‡è³‡æ–™é›¢æ•£åŒ–ç‚º {num_bins} å€‹ç´šè·ï¼Œè«‹å˜—è©¦ä¸åŒçš„ç´šè·æ•¸é‡")

st.markdown("---")
st.success("æ‰€æœ‰æ¨¡å‹åˆ†æåŠŸèƒ½å·²å»ºæ§‹å®Œæˆï¼")