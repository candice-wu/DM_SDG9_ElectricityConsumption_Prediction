import streamlit as st
import base64
import pandas as pd
import textwrap
from src.data_preprocessing import DataPreprocessor
from mlxtend.frequent_patterns import apriori, association_rules
from mlxtend.preprocessing import TransactionEncoder

st.set_page_config(page_title="è³‡æ–™åˆ†æ", page_icon="ğŸ“Š", layout="wide")

st.title("ğŸ“Š è³‡æ–™æ•´åˆåˆ†æ (Data Integration Analysis)")

# Helper function to generate conclusions for plots
def generate_analysis_conclusion(plot_type, analysis_data, encoders=None):
    conclusion_text = ""
    if plot_type == 'linear_regression':
        stats = analysis_data['linear_regression_stats']
        slope = stats['slope']
        r_squared = stats['r_squared']
        p_value = stats['p_value']

        if p_value < 0.05:
            sig_text = "çµ±è¨ˆçµæœé¡¯è‘—"
        else:
            sig_text = "çµ±è¨ˆçµæœä¸é¡¯è‘—"

        conclusion_text += f"- **ç›¸é—œæ€§å¼·åº¦**ï¼šæ­¤æ¨¡å‹ R-squared (RÂ²) = <span style='color:#4481D7'>**{r_squared:.4f}**</span> è¡¨ç¤ºæ­¤æ¨¡å‹è§£é‡‹ç”¨é›»é‡ç´„ <span style='color:#4481D7'>**{r_squared*100:.4f}%**</span> çš„è®Šç•°ï¼Œå³æœˆå‡æº«èˆ‡ç”¨é›»é‡ä¹‹é–“å­˜åœ¨ä¸­ç­‰è‡³å¼·çš„ç·šæ€§é—œä¿‚\n"
        conclusion_text += f"- **é—œä¿‚æ–¹å‘**ï¼šæ­¤æ¨¡å‹æ–œç‡ (Slopeï½œCoefficient) = <span style='color:#4481D7'>**{slope:.4f}**</span>ï¼Œè¡¨ç¤ºæœˆå‡æº«æ¯å¢åŠ  1 å–®ä½ï¼Œç”¨é›»é‡å¹³å‡å¢åŠ ç´„ <span style='color:#4481D7'>**{slope:.4f}**</span> è¬KW\n"
        if slope > 0:
            conclusion_text += "- **è¶¨å‹¢**ï¼šæ­¤æ¨¡å‹å‘ˆç¾<span style='color:#4481D7'>**æ­£å‘é—œä¿‚**</span>ï¼Œå³æœˆå‡æº«å‡é«˜æ™‚ï¼Œç”¨é›»é‡å‚¾å‘æ–¼å¢åŠ \n"
        else:
            conclusion_text += "- **è¶¨å‹¢**ï¼šæ­¤æ¨¡å‹å‘ˆç¾<span style='color:#4481D7'>**è² å‘é—œä¿‚**</span>ï¼Œå³æœˆå‡æº«å‡é«˜æ™‚ï¼Œç”¨é›»é‡å‚¾å‘æ–¼æ¸›å°‘\n"
        
        if p_value < 0.01:
            conclusion_text += f"- **çµ±è¨ˆçµæœ**ï¼šæ­¤æ¨¡å‹ p-value = <span style='color:#4481D7'>**{p_value:.4f}**</span> ï¼Œæœ‰å¼·çƒˆè­‰æ“šæ”¯æŒæœˆå‡æº«èˆ‡ç”¨é›»é‡ä¹‹é–“å­˜åœ¨ç·šæ€§é—œä¿‚\n"
        elif p_value < 0.05:
            conclusion_text += f"- **çµ±è¨ˆçµæœ**ï¼šæ­¤æ¨¡å‹ p-value = <span style='color:#4481D7'>**{p_value:.4f}**</span>ï¼Œæœ‰é©åº¦è­‰æ“šæ”¯æŒæœˆå‡æº«èˆ‡ç”¨é›»é‡ä¹‹é–“å­˜åœ¨ç·šæ€§é—œä¿‚\n"
        else:
            conclusion_text += f"- **çµ±è¨ˆçµæœ**ï¼šæ­¤æ¨¡å‹ p-value = <span style='color:#4481D7'>**{p_value:.4f}**</span>ï¼Œç„¡è¶³å¤ è­‰æ“šæ”¯æŒæœˆå‡æº«èˆ‡ç”¨é›»é‡ä¹‹é–“å­˜åœ¨ç·šæ€§é—œä¿‚\n"

    elif plot_type == 'residual_plot':
        st.markdown("##### **æ®˜å·®åœ–è§€å¯Ÿé‡é»**")
        st.markdown("- <span style='color:#4481D7'>**é›¶é»æ°´å¹³ç·š**</span>ï¼šç†æƒ³çš„æ®˜å·®æ‡‰è©²åœç¹æ­¤ç·šéš¨æ©Ÿåˆ†ä½ˆ", unsafe_allow_html=True)
        st.markdown("- <span style='color:#4481D7'>**éç·šæ€§é—œä¿‚**</span>ï¼šè‹¥æ®˜å·®å‘ˆç¾æ›²ç·šå½¢æ…‹ï¼Œå¯èƒ½æš—ç¤ºè®Šæ•¸é–“å­˜åœ¨éç·šæ€§é—œä¿‚ï¼Œå¯è€ƒæ…®æ›´è¤‡é›œçš„æ¨¡å‹æˆ–è³‡æ–™è½‰æ›", unsafe_allow_html=True)
        st.markdown("- <span style='color:#4481D7'>**ç•°æ–¹å·®æ€§**</span>ï¼šè‹¥æ®˜å·®å‘ˆç¾å–‡å­å½¢æˆ–æ¼æ–—å½¢åˆ†ä½ˆï¼Œå¯èƒ½æš—ç¤ºèª¤å·®è®Šç•°æ•¸éæ†å®šï¼Œå¯è€ƒæ…®æ›´è¤‡é›œçš„æ¨¡å‹æˆ–è³‡æ–™è½‰æ›", unsafe_allow_html=True)

    elif plot_type == 'boxplot':
        median_data = analysis_data
        col_name = median_data.name
        
        if encoders and col_name in encoders:
            original_labels = {i: label for i, label in enumerate(encoders[col_name])}
            median_data.index = median_data.index.map(original_labels)

        if not median_data.empty:
            highest_median_cat = median_data.index[0]
            highest_median_val = median_data.iloc[0]
            lowest_median_cat = median_data.index[-1]
            lowest_median_val = median_data.iloc[-1]
            median_range = highest_median_val - lowest_median_val

            st.markdown(f"##### **{col_name} ç”¨é›»é‡ä¸­ä½æ•¸æ’åºï¼š**")
            median_df = pd.DataFrame({'é¡åˆ¥': median_data.index, 'ç”¨é›»é‡ä¸­ä½æ•¸ï¼ˆè¬KWï¼‰': median_data.values})
            st.dataframe(median_df.style.format({'ç”¨é›»é‡ä¸­ä½æ•¸ï¼ˆè¬KWï¼‰': '{:.4f}'}))
            conclusion_text += f"- **ä¸­ä½æ•¸ç¯„åœ**ï¼šå„é¡åˆ¥ç”¨é›»é‡ä¸­ä½æ•¸å·®ç•°ç‚º <span style='color:#4481D7'>**{median_range:.4f}**</span> è¬KWï¼Œé¡¯ç¤ºè©²é¡åˆ¥å°ç”¨é›»é‡æœ‰ä¸åŒç¨‹åº¦çš„å½±éŸ¿"
        else:
            conclusion_text += "ç„¡æ³•è¨ˆç®—æ­¤é¡åˆ¥çš„çµè«–"
    return conclusion_text

# Function to generate plots, cached
@st.cache_data
def generate_integration_plots(_preprocessor):
    try:
        return _preprocessor.integrate_data()
    except Exception as e:
        st.error(f"ç”Ÿæˆåœ–è¡¨æ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")
        return None, None

def generate_rules_summary(sorted_rules_df):
    """Generates a human-readable summary of the top association rules from a pre-sorted DataFrame."""
    if sorted_rules_df.empty:
        return ""

    summary = "#### ğŸš¨ åˆ†ææ‘˜è¦ (Analysis Summary)\n\n"
    top_rules = sorted_rules_df.head(3)

    for index, rule in top_rules.iterrows():
        # Correctly format antecedents and consequents with highlighting
        antecedents = ', '.join([f"<span style='color:#9ACD32'>**{item.replace('=', 'ç‚º')}**</span>" for item in rule['antecedents']])
        consequents = ', '.join([f"<span style='color:#9ACD32'>**{item.replace('=', 'ç‚º')}**</span>" for item in rule['consequents']])
        lift = rule['lift']
        confidence = rule['confidence']

        summary += f"**è¦å‰‡ {index}ï¼š**\n"
        summary += f"> ç•¶ {antecedents} æ™‚ï¼Œå¯ä»¥ç™¼ç¾ {consequents} çš„å¯èƒ½æ€§ä¹Ÿéš¨ä¹‹æé«˜ã€‚\n"
        
        if lift > 1.5:
            lift_desc = f"æ­¤è¦å‰‡çš„å¢ç›Š (Lift) å€¼é«˜é” <span style='color:#9ACD32'>**{lift:.4f}**</span>ï¼Œé€™ä»£è¡¨ä¸€å€‹**éå¸¸å¼·**çš„æ­£ç›¸é—œï¼Œæ„è¬‚è‘—é€™å…©ä»¶äº‹åŒæ™‚ç™¼ç”Ÿçš„æ©Ÿç‡é é«˜æ–¼å¶ç„¶ã€‚"
        else:
            lift_desc = f"æ­¤è¦å‰‡çš„å¢ç›Š (Lift) å€¼ç‚º <span style='color:#9ACD32'>**{lift:.4f}**</span>ï¼Œå‘ˆç¾æ­£ç›¸é—œã€‚"
        
        # Clean up the HTML string for confidence description
        conf_antecedents = antecedents.replace("<span style='color:#9ACD32'>**", "").replace("**</span>", "")
        conf_consequents = consequents.replace("<span style='color:#9ACD32'>**", "").replace("**</span>", "")
        conf_desc = f"å…¶ä¿¡è³´åº¦ (Confidence) ç‚º <span style='color:#9ACD32'>**{confidence:.4%}**</span>ï¼Œè¡¨ç¤ºåœ¨æ»¿è¶³ã€Œ{conf_antecedents}ã€é€™å€‹æ¢ä»¶çš„è³‡æ–™ä¸­ï¼Œæœ‰ <span style='color:#9ACD32'>**{confidence:.4%}**</span> çš„æƒ…æ³ä¹Ÿæœƒæ»¿è¶³ã€Œ{conf_consequents}ã€ã€‚\n\n"
        
        summary += f"{lift_desc} {conf_desc}"

    return summary


# Check for data availability
if 'cleaned_df' not in st.session_state or 'preprocessor' not in st.session_state:
    st.warning("â¬…ï¸ è«‹å…ˆè‡³ã€ŒğŸ“„ è³‡æ–™æ¢ç´¢èˆ‡æ¸…ç†ã€é é¢ä¸Šå‚³ä¸¦æ¸…ç†è³‡æ–™")
    st.stop()

st.info("æ­¤é é¢æä¾›å¤šç¨®è³‡æ–™åˆ†ææ–¹æ³•ï¼Œè«‹åœ¨ä¸‹æ–¹é¸æ“‡åˆ†é é€²è¡Œæ¢ç´¢ã€‚", icon="â„¹ï¸")

# Get preprocessor and original cleaned df
preprocessor = st.session_state['preprocessor']
cleaned_df = st.session_state['cleaned_df']

# Create tabs
tab1, tab2 = st.tabs(["ğŸ“Š æ¢ç´¢å¼è³‡æ–™åˆ†æ (Exploratory Data Analysis)", "ğŸ§º é—œè¯è¦å‰‡åˆ†æ (Association Rule Mining)"])

with tab1:
    plots, analysis_results = generate_integration_plots(preprocessor)
    if plots and analysis_results:
        st.markdown("<h3>ğŸ’  ç‰¹å¾µç›¸é—œæ€§åˆ†æï¼ˆCorrelation Analysisï¼‰</h3>", unsafe_allow_html=True)
        st.markdown("<h4>ğŸŒ¡ï¸ ç›¸é—œæ€§ç†±åœ– ï¼ˆAnnotated Heatmapï¼‰</h4>", unsafe_allow_html=True)
        st.markdown(textwrap.dedent("""
                    ç›¸é—œæ€§åˆ†æç”¨æ–¼è¡¡é‡å…©å€‹æˆ–å¤šå€‹è®Šæ•¸ä¹‹é–“çš„çµ±è¨ˆé—œä¿‚å¼·åº¦èˆ‡æ–¹å‘
                    - é¡è‰²æ„ˆæ¥è¿‘ <span style='color:#4481D7'>**1**</span> æˆ–
                      <span style='color:#4481D7'>**-1**</span>ï¼Œ
                      è¡¨ç¤ºè®Šæ•¸ä¹‹é–“çš„ç·šæ€§é—œä¿‚æ„ˆ<span style='color:#4481D7'>**å¼·**</span>
                    - é¡è‰²æ„ˆæ¥è¿‘ <span style='color:#4481D7'>**0**</span>ï¼Œ
                      è¡¨ç¤ºè®Šæ•¸ä¹‹é–“çš„ç·šæ€§é—œä¿‚æ„ˆ<span style='color:#4481D7'>**å¼±**</span>
                    """), unsafe_allow_html=True)
        st.image(f"data:image/png;base64,{plots['correlation_heatmap']}", caption="ç‰¹å¾µç›¸é—œæ€§ç†±åœ–")
        
        with st.expander("ğŸ“Š çµè«–ï¼šç‰¹å¾µç›¸é—œæ€§åˆ†æ"):
            corr_matrix = analysis_results['correlation_matrix']
            if corr_matrix is not None:
                corr_with_target = corr_matrix['Electricity_Usage'].sort_values(ascending=False).drop('Electricity_Usage')
                
                st.markdown("##### **æ‰€æœ‰ç‰¹å¾µèˆ‡ç”¨é›»é‡ä¹‹ç›¸é—œä¿‚æ•¸æ’åºï¼š**")
                st.dataframe(corr_with_target.reset_index().rename(columns={'index': 'ç‰¹å¾µ', 'Electricity_Usage': 'ç›¸é—œä¿‚æ•¸'}).style.format({'ç›¸é—œä¿‚æ•¸': '{:.4f}'}))
                
                st.markdown("å¾ä¸Šæ–¹çš„ç†±åœ–èˆ‡ç›¸é—œä¿‚æ•¸è¡¨ï¼Œå¯ä»¥çœ‹å‡ºèˆ‡ã€Œç”¨é›»é‡ã€æœ€ç›¸é—œçš„å¹¾å€‹è®Šæ•¸ï¼š")
                
                top_positive = corr_with_target.nlargest(3, keep='all')
                st.markdown("##### **æ­£ç›¸é—œ** (æ•¸å€¼æ„ˆå¤§ï¼Œç”¨é›»é‡å¯èƒ½æ„ˆé«˜)ï¼š")
                for feature, corr_value in top_positive.items():
                    st.markdown(f"- <span style='color:#4481D7'>**{feature}**</span>ï¼šç›¸é—œä¿‚æ•¸ç‚º <span style='color:#4481D7'>**{corr_value:.4f}**</span>", unsafe_allow_html=True)
                
                top_negative = corr_with_target.nsmallest(3, keep='all').sort_values()
                st.markdown("##### **è² ç›¸é—œ** (æ•¸å€¼æ„ˆå¤§ï¼Œç”¨é›»é‡å¯èƒ½æ„ˆä½)ï¼š")
                for feature, corr_value in top_negative.items():
                     st.markdown(f"- <span style='color:#4481D7'>**{feature}**</span>ï¼šç›¸é—œä¿‚æ•¸ç‚º <span style='color:#4481D7'>**{corr_value:.4f}**</span>", unsafe_allow_html=True)
            else:
                st.markdown("ç„¡æ³•è¨ˆç®—ç›¸é—œæ€§çŸ©é™£ã€‚")

        st.divider()
        st.markdown("<h3>ğŸ”¢ æ•¸å€¼å‹è®Šæ•¸èˆ‡ç”¨é›»é‡é—œä¿‚ (Numerical Variables & Electricity Usage)</h3>", unsafe_allow_html=True)
        st.markdown("<h4>ğŸ“ˆ ç·šæ€§è¿´æ­¸åœ–ï¼ˆLinear Regression Plotï¼‰</h4>", unsafe_allow_html=True)
        st.markdown("é¡¯ç¤ºå…©å€‹æ•¸å€¼å‹è®Šæ•¸ä¹‹é–“çš„ç·šæ€§é—œä¿‚ï¼Œä¸¦åŒ…å«è¿´æ­¸ç·šèˆ‡é‚Šéš›åˆ†ä½ˆåœ–")
        if 'jointplot_reg' in plots:
            st.image(f"data:image/png;base64,{plots['jointplot_reg']}", caption="ç·šæ€§è¿´æ­¸æš¨é‚Šéš›åˆ†ä½ˆåœ–")
        
        with st.expander("ğŸ“Š çµè«–ï¼šç·šæ€§è¿´æ­¸åˆ†æ"):
            st.markdown(textwrap.dedent("""
            ##### æ–¹æ³•å®šç¾©
            é¡¯ç¤ºå…©å€‹æ•¸å€¼å‹è®Šæ•¸ä¹‹é–“çš„ç·šæ€§é—œä¿‚ï¼Œä¸¦åŒ…å«è¿´æ­¸ç·šèˆ‡é‚Šéš›åˆ†ä½ˆåœ–
            - **è¿´æ­¸ç·š**ï¼šã€Œç´…è‰²å¯¦ç·šã€è¡¨ç¤ºè³‡æ–™çš„æœ€ä½³æ“¬åˆç·šï¼›ã€Œç´…è‰²å¯¦ç·šçš„æ–œç‡ã€è¡¨ç¤ºå…©å€‹è®Šæ•¸ä¹‹é–“çš„é—œä¿‚ï¼š
                - <span style='color:#4481D7'>**æ­£æ–œç‡**</span>ï¼šè¡¨ç¤ºä¸€å€‹è®Šæ•¸å¢åŠ æ™‚ï¼Œå¦ä¸€å€‹è®Šæ•¸ä¹Ÿå‚¾å‘æ–¼å¢åŠ 
                - <span style='color:#4481D7'>**è² æ–œç‡**</span>ï¼šè¡¨ç¤ºä¸€å€‹è®Šæ•¸å¢åŠ æ™‚ï¼Œå¦ä¸€å€‹è®Šæ•¸å»å‚¾å‘æ–¼æ¸›å°‘
            - **æ•£ä½ˆé»**ï¼šã€Œè—è‰²é»ã€è¡¨ç¤ºå€‹åˆ¥è³‡æ–™é»
                - è³‡æ–™é»æ„ˆæ¥è¿‘ <span style='color:#4481D7'>**è¿´æ­¸ç·š**</span>ï¼Œè¡¨ç¤ºç·šæ€§é—œä¿‚æ„ˆ<span style='color:#4481D7'>**å¼·**</span>
            - **é‚Šéš›åˆ†ä½ˆåœ–**ï¼šä¸Šæ–¹å’Œå³å´çš„ç›´æ–¹åœ–é¡¯ç¤ºå–®ç¨è®Šæ•¸çš„åˆ†ä½ˆæƒ…æ³
            """), unsafe_allow_html=True)
            st.markdown("---")
            st.markdown("##### **æ•¸æ“šç‰¹æ€§**")
            st.markdown(generate_analysis_conclusion('linear_regression', analysis_results), unsafe_allow_html=True)

        st.markdown("<h4>ğŸ“‰ æ®˜å·®åœ–ï¼ˆResidual Plotï¼‰</h4>", unsafe_allow_html=True)
        st.markdown(textwrap.dedent("""
                    æ®˜å·®åœ–é¡¯ç¤ºã€Œè§€æ¸¬çš„é æ¸¬å€¼ã€èˆ‡ã€Œè§€æ¸¬çš„æ®˜å·®ã€ä¹‹é–“çš„é—œä¿‚ï¼Œ
                    æœ‰åŠ©æ–¼è©•ä¼°è¿´æ­¸æ¨¡å‹çš„é©ç”¨æ€§ä¸¦æª¢æŸ¥æ˜¯å¦å­˜åœ¨éç·šæ€§é—œä¿‚æˆ–ç•°æ–¹å·®æ€§
                    - è§€æ¸¬çš„æ®˜å·®ï¼šé æ¸¬å›æ‡‰å€¼èˆ‡å¯¦éš›å›æ‡‰å€¼ä¹‹é–“çš„å·®ç•°
                    """))
        st.image(f"data:image/png;base64,{plots['residual_temp_vs_elec']}", caption="æœˆå‡æº«èˆ‡ç”¨é›»é‡æ®˜å·®åœ–")

        with st.expander("ğŸ“Š çµè«–ï¼šæ®˜å·®åˆ†æ"):
            st.markdown(generate_analysis_conclusion('residual_plot', None), unsafe_allow_html=True)

        st.divider()
        st.markdown("<h3>ğŸ”– é¡åˆ¥å‹è®Šæ•¸èˆ‡ç”¨é›»é‡é—œä¿‚ (Categorical Variables & Electricity Usage)</h3>", unsafe_allow_html=True)
        st.markdown("<h4>ğŸ“¦ ç›’é¬šåœ–ï¼ˆBox Plotï¼‰</h4>", unsafe_allow_html=True)
        st.markdown(textwrap.dedent("""
                    ç›’é¬šåœ–æ˜¯ä¸€ç¨®æ¨™æº–åŒ–çš„æ–¹å¼ï¼Œç”¨æ–¼é¡¯ç¤ºè³‡æ–™çš„åˆ†ä½ˆæƒ…æ³ã€é›†ä¸­è¶¨å‹¢å’Œè®Šç•°æ•¸
                    - å¯ä»¥æ¯”è¼ƒä¸åŒé¡åˆ¥è®Šæ•¸åœ¨ç”¨é›»é‡ä¸Šçš„åˆ†ä½ˆå·®ç•°
                    - å®ƒå°‡è³‡æ–™åˆ†ç‚ºã€Œå››åˆ†ä½æ•¸ã€ï¼Œèƒ½å¤ æ¸…æ¥šåœ°å±•ç¤ºè³‡æ–™çš„é›¢æ•£ç¨‹åº¦ã€åæ…‹å’Œç•°å¸¸å€¼
                    """))
        
        categorical_cols = ['Science_Park', 'Sub_Science_Park', 'County', 'Town']
        col1, col2 = st.columns(2)
        
        for i, col in enumerate(categorical_cols):
            target_col = col1 if i % 2 == 0 else col2
            with target_col:
                plot_key = f'boxplot_{col}_vs_elec'
                if plot_key in plots:
                    st.image(f"data:image/png;base64,{plots[plot_key]}", caption=f"{col} èˆ‡ç”¨é›»é‡ç›’é¬šåœ–")
                    with st.expander(f"ğŸ“Š {col} çµè«–"):
                        st.markdown(textwrap.dedent(f"""
                        ##### æ–¹æ³•å®šç¾©
                        é€éäº”æ•¸ç¶œè¿°ï¼ˆæœ€å°å€¼ã€ç¬¬ä¸€å››åˆ†ä½æ•¸ã€ä¸­ä½æ•¸ã€ç¬¬ä¸‰å››åˆ†ä½æ•¸ã€æœ€å¤§å€¼ï¼‰ä¾†å±•ç¤º <span style='color:#4481D7'>**{col}**</span> çš„ç”¨é›»é‡åˆ†ä½ˆã€é›†ä¸­è¶¨å‹¢å’Œé›¢æ•£ç¨‹åº¦
                        """), unsafe_allow_html=True)
                        st.markdown("---")
                        st.markdown("##### **æ•¸æ“šç‰¹æ€§**")
                        median_data = analysis_results.get('box_plot_analysis', {}).get(col)
                        if median_data is not None and not median_data.empty:
                            st.markdown(generate_analysis_conclusion('boxplot', median_data, preprocessor.encoders), unsafe_allow_html=True)
                        else:
                            st.markdown("ç„¡æ³•è¨ˆç®—æ­¤é¡åˆ¥çš„çµè«–ã€‚", unsafe_allow_html=True)
    else:
        st.error("ç„¡æ³•ç”Ÿæˆæˆ–è¼‰å…¥åˆ†æåœ–è¡¨ã€‚è«‹ç¢ºèªè³‡æ–™æ˜¯å¦æ­£ç¢ºã€‚")

with tab2:
    st.header("ğŸ›’ é—œè¯è¦å‰‡åˆ†æ (Association Rule Mining)")
    st.markdown(textwrap.dedent("""
        - å¸¸ç”¨æ–¼ã€Œå¸‚å ´è³¼ç‰©ç±ƒåˆ†æ (Market Basket Analysis)ã€ï¼Œæ—¨åœ¨ç™¼æ˜è³‡æ–™é›†ä¸­é …ç›®ä¹‹é–“çš„æœ‰è¶£é—œä¿‚
        - å°‡è³‡æ–™çš„æ¯å€‹ row è¦–ç‚ºä¸€ç­†äº¤æ˜“ï¼Œæ¯å€‹ç‰¹å¾µçš„æ•¸å€¼è¦–ç‚ºäº¤æ˜“ä¸­çš„ä¸€å€‹ã€Œé …ç›®ã€ï¼Œè—‰æ­¤æ‰¾å‡ºç‰¹å¾µä¹‹é–“çš„ `if-then` é—œè¯è¦å‰‡
    """), unsafe_allow_html=True)

    with st.container(border=True):
        st.subheader("âš™ï¸ åˆ†æè¨­å®š (Analysis Settings)")
        
        all_cols = ['Science_Park', 'Sub_Science_Park', 'County', 'Town', 'Year_EN', 'Month_NUM', 'Avg_Temperature', 'Electricity_Usage']
        
        selected_features = st.multiselect(
            '**1. é¸æ“‡è¦åˆ†æçš„ç‰¹å¾µ (Select Features for Analysis)**',
            options=all_cols,
            default=['Sub_Science_Park', 'Month_NUM', 'Avg_Temperature', 'Electricity_Usage'],
            help="é¸æ“‡æ‚¨æ„Ÿèˆˆè¶£çš„ç‰¹å¾µä¾†é€²è¡Œé—œè¯è¦å‰‡åˆ†æã€‚å»ºè­°ä¸è¦é¸æ“‡éå¤šç‰¹å¾µï¼Œä»¥å…è¦å‰‡éæ–¼è¤‡é›œã€‚"
        )

        st.markdown("**2. è¨­å®šé€£çºŒå‹è³‡æ–™çš„é›¢æ•£åŒ–å€é–“æ•¸ (Set Bins for Continuous Features)**")
        st.caption("âš ï¸ æ­¤æ­¥é©Ÿæ˜¯å°‡é€£çºŒæ•¸å€¼ï¼ˆå¦‚æº«åº¦ã€ç”¨é›»é‡ï¼‰è½‰æ›ç‚ºé¡åˆ¥ï¼ˆå¦‚é«˜ã€ä¸­ã€ä½ï¼‰ï¼Œé€™æ˜¯ Apriori æ¼”ç®—æ³•çš„å¿…è¦å‰ç½®è™•ç†ã€‚é è¨­å€¼ `3` ä»£è¡¨å°‡æ•¸å€¼åˆ†ç‚ºã€Œä½ã€ä¸­ã€é«˜ã€ä¸‰å€‹ç­‰ç´š")
        
        preprocessor = st.session_state['preprocessor']
        continuous_cols = [
            col for col in selected_features 
            if col not in preprocessor.encoders 
            and cleaned_df[col].dtype in ['float64', 'int64'] 
            and cleaned_df[col].nunique() > 10
        ]
        
        bins_config = {}
        if continuous_cols:
            col1, col2, col3 = st.columns(3)
            cols = [col1, col2, col3]
            for i, col in enumerate(continuous_cols):
                with cols[i % 3]:
                    bins_config[col] = st.number_input(f"`{col}` çš„å€é–“æ•¸", min_value=2, max_value=10, value=3, key=f"bins_{col}")
        else:
            st.info("æ‚¨é¸æ“‡çš„ç‰¹å¾µä¸­æ²’æœ‰éœ€è¦é›¢æ•£åŒ–çš„é€£çºŒå‹è³‡æ–™ã€‚")

        st.markdown("**3. è¨­å®š Apriori æ¼”ç®—æ³•åƒæ•¸ (Set Apriori Parameters)**")
        col1, col2 = st.columns(2)
        with col1:
            min_support = st.slider('æœ€ä½æ”¯æŒåº¦ (Min Support)', 0.01, 1.0, 0.05, 0.01, help="ä¸€å€‹é …ç›®é›†åœ¨æ‰€æœ‰äº¤æ˜“ä¸­å‡ºç¾çš„é »ç‡ã€‚è¼ƒé«˜çš„å€¼æœƒç¯©é¸æ‰ä¸å¸¸è¦‹çš„é …ç›®é›†ã€‚")
        with col2:
            min_confidence = st.slider('æœ€å°ä¿¡è³´åº¦ (Min Confidence)', 0.1, 1.0, 0.5, 0.1, help="è¦å‰‡çš„å¯é æ€§æŒ‡æ¨™ã€‚`IF {A} THEN {B}` çš„ä¿¡è³´åº¦æ˜¯æŒ‡äº¤æ˜“ä¸­åŒ…å« A æ™‚ï¼Œä¹ŸåŒ…å« B çš„æ©Ÿç‡ã€‚")

        run_button = st.button('ğŸš€ åŸ·è¡Œé—œè¯è¦å‰‡åˆ†æ', type="primary", use_container_width=True)

    if 'rules_df' not in st.session_state:
        st.session_state.rules_df = pd.DataFrame()

    if run_button:
        if not selected_features:
            st.warning("è«‹è‡³å°‘é¸æ“‡ä¸€å€‹ç‰¹å¾µé€²è¡Œåˆ†æã€‚")
        else:
            with st.spinner('æ­£åœ¨é€²è¡Œåˆ†æï¼Œè«‹ç¨å€™...'):
                try:
                    df_apriori = cleaned_df[selected_features].copy()

                    # Inverse transform categorical data to get original labels
                    preprocessor = st.session_state['preprocessor']
                    for col in df_apriori.columns:
                        if col in preprocessor.encoders:
                            # The encoder is a list of categories. The data is the integer code.
                            # We map the integer code back to the string category.
                            # df.cat.codes uses -1 for NaN, so we handle that.
                            category_list = preprocessor.encoders[col]
                            df_apriori[col] = df_apriori[col].astype(int).apply(lambda x: category_list[x] if x >= 0 and x < len(category_list) else 'N/A')

                    bin_labels = {2: ['Low', 'High'], 3: ['Low', 'Medium', 'High'], 4: ['Lowest', 'Low', 'High', 'Highest']}
                    for col, bins in bins_config.items():
                        labels = bin_labels.get(bins, [f"Bin_{i}" for i in range(bins)])
                        df_apriori[col] = pd.qcut(df_apriori[col], q=bins, labels=labels, duplicates='drop')

                    transactions = [
                        [f"{col}={df_apriori[col].iloc[i]}" for col in df_apriori.columns]
                        for i in range(len(df_apriori))
                    ]
                    
                    te = TransactionEncoder()
                    te_ary = te.fit(transactions).transform(transactions)
                    df_encoded = pd.DataFrame(te_ary, columns=te.columns_)

                    frequent_itemsets = apriori(df_encoded, min_support=min_support, use_colnames=True)

                    if frequent_itemsets.empty:
                        st.warning("åœ¨æ­¤æ”¯æŒåº¦è¨­å®šä¸‹ï¼Œæ‰¾ä¸åˆ°ä»»ä½•é«˜é »é …ç›®é›†ã€‚è«‹å˜—è©¦èª¿ä½ã€Œæœ€ä½æ”¯æŒåº¦ã€ã€‚")
                        st.session_state.rules_df = pd.DataFrame()
                    else:
                        rules = association_rules(frequent_itemsets, metric="confidence", min_threshold=min_confidence)
                        if rules.empty:
                            st.warning("é›–ç„¶æ‰¾åˆ°äº†é«˜é »é …ç›®é›†ï¼Œä½†åœ¨ç›®å‰çš„ä¿¡è³´åº¦è¨­å®šä¸‹ï¼Œç„¡æ³•ç”Ÿæˆä»»ä½•é—œè¯è¦å‰‡ã€‚è«‹å˜—è©¦èª¿ä½ã€Œæœ€å°ä¿¡è³´åº¦ã€ã€‚")
                            st.session_state.rules_df = pd.DataFrame()
                        else:
                            st.success(f"åˆ†æå®Œæˆï¼å…±æ‰¾åˆ° {len(rules)} æ¢é—œè¯è¦å‰‡ã€‚")
                            st.session_state.rules_df = rules.sort_values(by='lift', ascending=False).reset_index(drop=True)

                except Exception as e:
                    st.error(f"åˆ†æéç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")
                    st.session_state.rules_df = pd.DataFrame()

    if not st.session_state.rules_df.empty:
        st.subheader("â›³ é—œè¯è¦å‰‡çµæœ (Association Rules)")
        st.dataframe(st.session_state.rules_df)

        st.markdown("---")
        summary = generate_rules_summary(st.session_state.rules_df)
        st.markdown(summary, unsafe_allow_html=True)
        
        with st.expander("ğŸ“– å¦‚ä½•è§£è®€é—œè¯è¦å‰‡ï¼Ÿ"):
            st.markdown("""
            - **antecedents (å‰é …)**ï¼šè¦å‰‡çš„ "IF" éƒ¨åˆ†
            - **consequents (å¾Œé …)**ï¼šè¦å‰‡çš„ "THEN" éƒ¨åˆ†
            - **support (æ”¯æŒåº¦)**ï¼šè¦å‰‡ä¸­ã€Œå‰é …å’Œå¾Œé …ä¸€èµ·å‡ºç¾ã€çš„äº¤æ˜“æ¯”ä¾‹ï¼Œåæ˜ è¦å‰‡åœ¨æ•´é«”è³‡æ–™ä¸­çš„æ™®éæ€§
            - **confidence (ä¿¡è³´åº¦)**ï¼šåœ¨åŒ…å«ã€Œå‰é …ã€çš„äº¤æ˜“ä¸­ï¼ŒåŒæ™‚ä¹ŸåŒ…å«ã€Œå¾Œé …ã€çš„æ¯”ä¾‹ï¼Œå³è¡¡é‡è¦å‰‡çš„æº–ç¢ºæ€§
            - **lift (å¢ç›Š)**ï¼šè¡¡é‡ã€Œå¾Œé …ã€åœ¨çµ¦å®šã€Œå‰é …ã€çš„æƒ…æ³ä¸‹ï¼Œå…¶å‡ºç¾æ©Ÿç‡ç›¸å°æ–¼å…¶è‡ªèº«ç¨ç«‹å‡ºç¾æ©Ÿç‡çš„æå‡ç¨‹åº¦
                - **Lift > 1**ï¼šè¡¨ç¤ºå‰é …å’Œå¾Œé …å­˜åœ¨**æ­£ç›¸é—œ**ï¼Œå‰é …çš„ç™¼ç”Ÿï¼Œæœƒæå‡å¾Œé …ç™¼ç”Ÿçš„æ©Ÿç‡
                - **Lift < 1**ï¼šè¡¨ç¤ºå‰é …å’Œå¾Œé …å­˜åœ¨**è² ç›¸é—œ**ï¼Œå‰é …çš„ç™¼ç”Ÿï¼Œæœƒé™ä½å¾Œé …ç™¼ç”Ÿçš„æ©Ÿç‡
                - **Lift = 1**ï¼šè¡¨ç¤ºå‰é …å’Œå¾Œé …**ç›¸äº’ç¨ç«‹**ï¼Œæ²’æœ‰é—œè¯
            
            ---
            ##### **é€²éšæŒ‡æ¨™**
            - **representativity (ä»£è¡¨æ€§)**ï¼šè¡¡é‡è¦å‰‡åœ¨æ•´é«”è³‡æ–™ä¸­çš„ä»£è¡¨æ€§ï¼Œè¨ˆç®—æ–¹å¼ç‚º `support(A âˆª B) / support(B)`
                - å€¼æ¥è¿‘ 1ï¼šè¡¨ç¤ºè¦å‰‡å°å¾Œé …å…·æœ‰é«˜åº¦ä»£è¡¨æ€§
                - å€¼æ¥è¿‘ 0ï¼šè¡¨ç¤ºè¦å‰‡å°å¾Œé …çš„ä»£è¡¨æ€§è¼ƒä½
            - **leverage (æ§“æ¡¿ç‡)**ï¼šé‡æ¸¬å‰é …èˆ‡å¾Œé …åŒæ™‚å‡ºç¾çš„é »ç‡ï¼Œæ¯”ã€Œå‡è¨­å…©è€…ç¨ç«‹æ™‚çš„é æœŸé »ç‡ã€é«˜å‡ºå¤šå°‘
                - å€¼ç‚º 0ï¼šè¡¨ç¤ºç¨ç«‹
                - å¤§æ–¼ 0ï¼šè¡¨ç¤ºåŒæ™‚å‡ºç¾çš„é »ç‡é«˜æ–¼é æœŸ
            - **conviction (ç¢ºä¿¡åº¦)**ï¼šç”¨ä¾†è¡¡é‡ã€Œå‰é …ã€å°æ–¼ã€Œå¾Œé …ã€çš„å½±éŸ¿åŠ›ï¼Œä¸€å€‹é«˜ç¢ºä¿¡åº¦å€¼æ„å‘³è‘—å¾Œé …çš„ç™¼ç”Ÿé«˜åº¦ä¾è³´æ–¼å‰é …
                - ä¾‹å¦‚ï¼šè‹¥ `conviction` ç‚º 2ï¼Œè¡¨ç¤ºå¦‚æœè¦å‰‡æ²’æœ‰å¾Œé …ï¼Œå®ƒçš„å‡ºéŒ¯ç‡æœƒæ˜¯åŸä¾†çš„ 2 å€
            - **zhangs_metric (å¼µæ°æŒ‡æ¨™)**ï¼šä¸€å€‹ç¶œåˆæŒ‡æ¨™ï¼Œç¯„åœåœ¨ -1 åˆ° +1 ä¹‹é–“
                - å€¼æ¥è¿‘ +1ï¼šè¡¨ç¤ºå¼·æ­£ç›¸é—œ
                - å€¼æ¥è¿‘ -1ï¼šè¡¨ç¤ºå¼·è² ç›¸é—œ
                - å€¼æ¥è¿‘ 0ï¼šè¡¨ç¤ºç„¡é—œè¯
            - **jaccard (é›…å¡çˆ¾æŒ‡æ•¸)**ï¼šè¡¡é‡å‰é …å’Œå¾Œé …åŒæ™‚å‡ºç¾çš„é »ç‡èˆ‡è‡³å°‘æœ‰ä¸€å€‹å‡ºç¾çš„é »ç‡ä¹‹æ¯”
                - å€¼ä»‹æ–¼ 0 åˆ° 1 ä¹‹é–“ï¼Œå€¼æ„ˆå¤§è¡¨ç¤ºå…©è€…é—œè¯æ„ˆå¼·
            - **certainty (ç¢ºå®šæ€§)**ï¼šè¡¡é‡åœ¨å‰é …ç™¼ç”Ÿçš„æƒ…æ³ä¸‹ï¼Œå¾Œé …ç™¼ç”Ÿçš„å¢å¼·ç¨‹åº¦
                - å€¼ä»‹æ–¼ -1 åˆ° +1 ä¹‹é–“
                - æ­£å€¼ï¼šè¡¨ç¤ºå‰é …çš„ç™¼ç”Ÿå¢åŠ äº†å¾Œé …ç™¼ç”Ÿçš„å¯èƒ½æ€§
                - è² å€¼ï¼šè¡¨ç¤ºå‰é …çš„ç™¼ç”Ÿæ¸›å°‘äº†å¾Œé …ç™¼ç”Ÿçš„å¯èƒ½æ€§
            - **Kulczynski (åº«æ°æŒ‡æ¨™)**ï¼šè¡¡é‡å‰é …å’Œå¾Œé …ä¹‹é–“çš„å°ç¨±é—œè¯æ€§
                - å€¼ä»‹æ–¼ 0 åˆ° 1 ä¹‹é–“ï¼Œå€¼æ„ˆå¤§è¡¨ç¤ºé—œè¯æ„ˆå¼·
            """, unsafe_allow_html=True)
    elif run_button: # To ensure messages are shown after a run that results in an empty dataframe
        pass # The warnings are already shown inside the `if run_button` block